NCBI_API_KEY=your_ncbi_api_key_here
NCBI_EMAIL=your_email@example.com
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBED_MODEL=text-embedding-3-small
# Batch size for embedding requests (titles per API call)
OPENAI_EMBED_BATCH=500
# Toggle second-stage embedding re-rank (requires OPENAI_API_KEY)
# 1 = on, 0 = off
ENABLE_EMBED=1
UPDATE_MAPPINGS=true
ENVIRONMENT=development
ACCESS_PASSWORD=change_this_secure_password

# =========================
# Hybrid Retrieval Knobs
# =========================
# Total titles to collect (union across query variants) before local re-rank
TITLE_POOL_SIZE=2500

# Minimum titles to fetch per query variant (ensures coverage)
PER_QUERY_MIN=300

# How many abstracts to fetch after re-rank:
# abstracts_fetched = SECOND_STAGE_FACTOR * max_results_requested
SECOND_STAGE_FACTOR=4.0

# =========================
# ELink Expansion (optional coverage boost)
# =========================
# 1 = run ELink expansion; 0 = skip
ENABLE_ELINK=1

# Which ELink modes to use: similar (related), citedin (cited-by), references (reference list)
# Comma-separated list without spaces
ELINK_MODES=similar,citedin
